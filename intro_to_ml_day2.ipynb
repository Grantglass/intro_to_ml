{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning for Humanists Day 2: Case Study\n",
    "## Identifying Jim Crow Laws*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library for Importing CSV file into a Dataframe\n",
    "import pandas as pd\n",
    "# Library to split the data into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Libraries to process section_text Tokenize=find words, Stopwords=remove stopwords, Regular Expression=remove non-word characters, Lemmatize text\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# A transformer LengthExtractor to extract length of each sentences in the section_text\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "#Model Tuning Libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Evaluation Libraries\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Allows the use of display() for DataFrames\n",
    "from IPython.display import display\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "#Ignore warnings = clean notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Exploring the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('training_set_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>sample</th>\n",
       "      <th>James_Assessment</th>\n",
       "      <th>Explicit_Implicit_Extrinsic</th>\n",
       "      <th>type</th>\n",
       "      <th>sess</th>\n",
       "      <th>chapter_text</th>\n",
       "      <th>section_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>277:2</td>\n",
       "      <td>paschal</td>\n",
       "      <td>pre-existing</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>public laws</td>\n",
       "      <td>1879</td>\n",
       "      <td>CHAPTER 276 AN ACT TO AUTHORIZE THE BOARD OF E...</td>\n",
       "      <td>That the board of education of the counties of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28:4</td>\n",
       "      <td>paschal</td>\n",
       "      <td>pre-existing</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>public laws</td>\n",
       "      <td>1880</td>\n",
       "      <td>CHAPTER 27 AN ACT TO AUTHORIZE THE ESTABLISHME...</td>\n",
       "      <td>The special taxes thus levied and collected fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28:9</td>\n",
       "      <td>paschal</td>\n",
       "      <td>pre-existing</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>public laws</td>\n",
       "      <td>1880</td>\n",
       "      <td>CHAPTER 27 AN ACT TO AUTHORIZE THE ESTABLISHME...</td>\n",
       "      <td>The board of commissioners for the county of W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201:23</td>\n",
       "      <td>paschal</td>\n",
       "      <td>pre-existing</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>public laws</td>\n",
       "      <td>1881</td>\n",
       "      <td>CHAPTER 200 AN ACT TO REVISE AND CONSOLIDATE T...</td>\n",
       "      <td>The county board of education of every county ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201:33</td>\n",
       "      <td>paschal</td>\n",
       "      <td>pre-existing</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>public laws</td>\n",
       "      <td>1881</td>\n",
       "      <td>CHAPTER 200 AN ACT TO REVISE AND CONSOLIDATE T...</td>\n",
       "      <td>The county treasurer of each county shall repo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index reviewer        sample  James_Assessment  \\\n",
       "0   277:2  paschal  pre-existing                 1   \n",
       "1    28:4  paschal  pre-existing                 1   \n",
       "2    28:9  paschal  pre-existing                 1   \n",
       "3  201:23  paschal  pre-existing                 1   \n",
       "4  201:33  paschal  pre-existing                 1   \n",
       "\n",
       "   Explicit_Implicit_Extrinsic         type  sess  \\\n",
       "0                          1.0  public laws  1879   \n",
       "1                          1.0  public laws  1880   \n",
       "2                          1.0  public laws  1880   \n",
       "3                          1.0  public laws  1881   \n",
       "4                          1.0  public laws  1881   \n",
       "\n",
       "                                        chapter_text  \\\n",
       "0  CHAPTER 276 AN ACT TO AUTHORIZE THE BOARD OF E...   \n",
       "1  CHAPTER 27 AN ACT TO AUTHORIZE THE ESTABLISHME...   \n",
       "2  CHAPTER 27 AN ACT TO AUTHORIZE THE ESTABLISHME...   \n",
       "3  CHAPTER 200 AN ACT TO REVISE AND CONSOLIDATE T...   \n",
       "4  CHAPTER 200 AN ACT TO REVISE AND CONSOLIDATE T...   \n",
       "\n",
       "                                        section_text  \n",
       "0  That the board of education of the counties of...  \n",
       "1  The special taxes thus levied and collected fr...  \n",
       "2  The board of commissioners for the county of W...  \n",
       "3  The county board of education of every county ...  \n",
       "4  The county treasurer of each county shall repo...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the file was imported, we performed simple preprocessing on the text (these are outlined in the code bellow):\n",
    "* Replaced hyphenated and line broken words with unbroken words.\n",
    "* Removed section numbering from the law text (\"section_text\").\n",
    "* We used session or volume identified (\"csv\") information to extract a numeric year.  In the case of multi-year volumes (e.g. 1956-1957) the earlier year was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fix hyphenated words\n",
    "#data[\"chapter_text\"] = data.text.str.replace(r\"-[ \\|]+(?P<letter>[a-zA-Z])\",repl).astype(\"str\")\n",
    "#data[\"section_text\"] = data.section_text.str.replace(r\"-[ \\|]+(?P<letter>[a-zA-Z])\",repl).astype(\"str\")\n",
    "#data[\"section_text\"] = [re.sub(r'- *\\n+(\\w+ *)', r'\\1\\n',r) for r in data[\"section_text\"]]\n",
    "#Remove section titles (e.g. \"Sec. 1\") from law text.\n",
    "#data[\"start\"] = data.section_raw.str.len().fillna(0).astype(\"int\")\n",
    "#data[\"section_text\"] = data.apply(lambda x: x['section_text'][(x[\"start\"]):], axis=1).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1824 entries, 0 to 1823\n",
      "Data columns (total 9 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   index                        1824 non-null   object \n",
      " 1   reviewer                     1824 non-null   object \n",
      " 2   sample                       1824 non-null   object \n",
      " 3   James_Assessment             1824 non-null   int64  \n",
      " 4   Explicit_Implicit_Extrinsic  1816 non-null   float64\n",
      " 5   type                         1824 non-null   object \n",
      " 6   sess                         1824 non-null   object \n",
      " 7   chapter_text                 1824 non-null   object \n",
      " 8   section_text                 1824 non-null   object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 128.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['James_Assessment'] = data['James_Assessment'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1235\n",
       "1     589\n",
       "Name: James_Assessment, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['James_Assessment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 1824\n",
      "Jim Crow Laws: 589\n",
      "Non-Jim Crow Laws: 1235\n",
      "Percentage of Jim Crow Laws: 32.29166666666667%\n"
     ]
    }
   ],
   "source": [
    "# Total number of records\n",
    "n_records = len(data.index)\n",
    "\n",
    "# jim crow laws\n",
    "jim_crow_laws = len(data[data.James_Assessment == 1])\n",
    "\n",
    "# non-jim crow laws\n",
    "regular_laws = len(data[data.James_Assessment == 0])\n",
    "\n",
    "# Percent of Jim Crow Laws\n",
    "jimcrow_percent = (jim_crow_laws / float(n_records)) * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of records: {}\".format(n_records))\n",
    "print(\"Jim Crow Laws: {}\".format(jim_crow_laws))\n",
    "print(\"Non-Jim Crow Laws: {}\".format(regular_laws))\n",
    "print(\"Percentage of Jim Crow Laws: {}%\".format(jimcrow_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Preparing the Data\n",
    "Before data can be used as input for machine learning algorithms, it often must be cleaned, formatted, and restructured — this is typically known as **preprocessing**. Fortunately, for this dataset, there are no invalid or missing entries we must deal with, however, there are some qualities about certain features that must be adjusted. This preprocessing can help tremendously with the outcome and predictive power of nearly all learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target label\n",
    "features = dataframe['section_text']\n",
    "target = dataframe['James_Assessment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and Split Data\n",
    "Now all _categorical variables_ have been converted into numerical features, and all numerical features have been normalized. As always, we will now split the data (both features and their labels) into training and test sets. 80% of the data will be used for training and 20% for testing.\n",
    "\n",
    "Run the code cell below to perform this split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 1459 samples.\n",
      "Testing set has 365 samples.\n"
     ]
    }
   ],
   "source": [
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Text Processing\n",
    "# extract the english stopwords and save it to a variable\n",
    "stopword = stopwords.words('english')\n",
    "# define regular expression to identify non-ascii characters in text\n",
    "non_ascii_regex = r'[^\\x00-\\x7F]+'\n",
    "def tokenize(text):\n",
    "        \n",
    "    # use library re to replace non ascii characters by a space\n",
    "    text = re.sub(non_ascii_regex, ' ', text)  \n",
    "\n",
    "    # use word_tokenize to tokenize the sentences\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # instantiate an object of class WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # use a list comprehension to lemmatize the tokens and remove the the stopwords\n",
    "    clean_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stopword]\n",
    "\n",
    "    # return the tokens\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer of text = turning text into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A transformer LengthExtractor to extract length of each sentences in the section_text and make that a feature\n",
    "class LengthExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def compute_length(self, text):\n",
    "        sentence_list = word_tokenize(text)\n",
    "        return len(sentence_list)\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_length = pd.Series(X).apply(self.compute_length)\n",
    "        return pd.DataFrame(X_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 7, 'quick': 6, 'brown': 0, 'fox': 2, 'jumped': 3, 'over': 5, 'lazy': 4, 'dog': 1}\n",
      "(1, 8)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[1 1 1 1 1 1 1 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# list of text documents\n",
    "text = [\"The quick brown fox jumped over the lazy dog.\"]\n",
    "# create the transform\n",
    "vectorizer = CountVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "# encode document\n",
    "vector = vectorizer.transform(text)\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(type(vector))\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 8 words in the vocab, and therefore encoded vectors have a length of 8.\n",
    "\n",
    "We can then see that the encoded vector is a sparse matrix. Finally, we can see an array version of the encoded vector showing a count of 1 occurrence for each word except the (index and id 7) that has an occurrence of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 7, 'quick': 6, 'brown': 0, 'fox': 2, 'jumped': 3, 'over': 5, 'lazy': 4, 'dog': 1}\n",
      "[1.69314718 1.28768207 1.28768207 1.69314718 1.69314718 1.69314718\n",
      " 1.69314718 1.        ]\n",
      "(1, 8)\n",
      "[[0.36388646 0.27674503 0.27674503 0.36388646 0.36388646 0.36388646\n",
      "  0.36388646 0.42983441]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# list of text documents\n",
    "text = [\"The quick brown fox jumped over the lazy dog.\", \"The dog.\", \"The fox\"]\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "# summarize\n",
    "print(vectorizer.vocabulary_)\n",
    "print(vectorizer.idf_)\n",
    "# encode document\n",
    "vector = vectorizer.transform([text[0]])\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vocabulary of 8 words is learned from the documents and each word is assigned a unique integer index in the output vector.\n",
    "\n",
    "The inverse document frequencies are calculated for each word in the vocabulary, assigning the lowest score of 1.0 to the most frequently observed word: “the” at index 7.\n",
    "\n",
    "Finally, the first document is encoded as an 8-element sparse array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Training our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Training and Predicting Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of Pipeline class\n",
    "pipeline = Pipeline([\n",
    "    \n",
    "        # create a FeatureUnion pipeline\n",
    "        ('features', FeatureUnion([\n",
    "\n",
    "            # add a pipeline element to extract features using CountVectorizer and TfidfTransformer\n",
    "            ('text_pipleline', Pipeline([\n",
    "                ('vect', CountVectorizer(decode_error = \"ignore\",\n",
    "                      min_df = 2, max_df = 1000)),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "            ])),\n",
    "            \n",
    "            # add the pipeline element - LengthExtractor to extract lenght of each sentence as feature\n",
    "            ('text_len', LengthExtractor()),\n",
    "        ])),\n",
    "\n",
    "        # use the predictor estimator RandomForestClassifier to train the model\n",
    "        ('dlf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our model’s prediction\n",
    "\n",
    "https://towardsdatascience.com/understanding-random-forest-58381e0602d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('features',\n",
       "                 FeatureUnion(transformer_list=[('text_pipleline',\n",
       "                                                 Pipeline(steps=[('vect',\n",
       "                                                                  CountVectorizer(decode_error='ignore',\n",
       "                                                                                  max_df=1000,\n",
       "                                                                                  min_df=2)),\n",
       "                                                                 ('tfidf',\n",
       "                                                                  TfidfTransformer())])),\n",
       "                                                ('text_len',\n",
       "                                                 LengthExtractor())])),\n",
       "                ('dlf', RandomForestClassifier())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run the Model\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Supervised Learning Models\n",
    "**The following are some of the supervised learning models that are currently available in** [`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html) **that you may choose from:**\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Decision Trees\n",
    "- Ensemble Methods (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Stochastic Gradient Descent Classifier (SGDC)\n",
    "- Support Vector Machines (SVM)\n",
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Predictor Performace\n",
    "* If we chose a model that always predicted if a law was jim crow, what would  that model's accuracy and F-score be on this dataset?\n",
    "\n",
    "** Please note ** that the the purpose of generating a naive predictor is simply to show what a base model without any intelligence would look like. In the real world, ideally your base model would be either the results of a previous model or could be based on a research paper upon which you are looking to improve. When there is no benchmark model set, getting a result better than random choice is a place you could start from.\n",
    "\n",
    "** NOTE: ** \n",
    "\n",
    "* When we have a model that always predicts '1' (i.e. there is always a jim crow law) then our model will have no True Negatives(TN) or False Negatives(FN) as we are not making any negative('0' value) predictions. Therefore our Accuracy in this case becomes the same as our Precision(True Positives/(True Positives + False Positives)) as every prediction that we have made with value '1' that should have '0' becomes a False Positive; therefore our denominator in this case is the total number of records we have in total. \n",
    "* Our Recall score(True Positives/(True Positives + False Negatives)) in this setting becomes 1 as we have no False Negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Predictor: [Accuracy score: 0.3229, F-score: 0.3735]\n"
     ]
    }
   ],
   "source": [
    "#Calculate Accuracy, Recall, Precision\n",
    "accuracy = (np.sum(target)) / ((np.sum(target)) + float(((target.count()) - np.sum(target))))\n",
    "recall = np.sum(target) / float((np.sum(target) + 0))\n",
    "precision = np.sum(target) / float(((np.sum(target) + ((target.count()) - np.sum(target)))))\n",
    "\n",
    "#Calculate F-score using the formula above for beta = 0.5 and correct values for precision and recall.\n",
    "beta = 0.5\n",
    "fscore = (1+ beta**2) * (precision * recall) / ((beta ** 2 * precision) + recall)\n",
    "\n",
    "#Print the results \n",
    "print(\"Naive Predictor: [Accuracy score: {:.4f}, F-score: {:.4f}]\".format(accuracy, fscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is accuracy, precision, recall?\n",
    "\n",
    "** Accuracy ** measures how often the classifier makes the correct prediction. It’s the ratio of the number of correct predictions to the total number of predictions (the number of test data points).\n",
    "\n",
    "** Precision ** tells us what proportion of messages we classified as Jim Crow, actually were Jim Crow.\n",
    "It is a ratio of true positives(laws classified as Jim Crow, and which are actually Jim Crow) to all positives(all laws classified as Jim Crow, irrespective of whether that was the correct classificatio), in other words it is the ratio of\n",
    "\n",
    "`[True Positives/(True Positives + False Positives)]`\n",
    "\n",
    "** Recall(sensitivity)** tells us what proportion of laws that actually were Jim Crow were classified by us as Jim Crow.\n",
    "It is a ratio of true positives(laws classified as Jim Crow, and which are actually Jim Crow) to all the laws that were actually Crow, in other words it is the ratio of\n",
    "\n",
    "`[True Positives/(True Positives + False Negatives)]`\n",
    "\n",
    "These two metrics can be combined to get the F1 score, which is weighted average(harmonic mean) of the precision and recall scores. This score can range from 0 to 1, with 1 being the best possible F1 score(we take the harmonic mean as we are dealing with ratios). We can use **F-beta score** as a metric that considers both precision and recall:\n",
    "\n",
    "\n",
    "$$ F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{precision \\cdot recall}{\\left( \\beta^2 \\cdot precision \\right) + recall} $$\n",
    "\n",
    "In particular, when $\\beta = 0.5$, more emphasis is placed on precision. This is called the **F$_{0.5}$ score** (or F-score for simplicity).\n",
    "\n",
    "Another Resource for understanding this report: https://medium.com/@kohlishivam5522/understanding-a-classification-report-for-your-machine-learning-model-88815e2ce397\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Predictions on the Test Data\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 1.0, 'Overall')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# count the number of labels\n",
    "labels = np.unique(y_pred)\n",
    "\n",
    "data = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
    "df_cm.index.name = 'Actual'\n",
    "df_cm.columns.name = 'Predicted'\n",
    "\n",
    "# use sns.heatmap on top of confusion_matrix to show the confusion matrix\n",
    "ax = sns.heatmap(df_cm,xticklabels=True, annot=True, fmt='.0f')\n",
    "ax.set(title=\"Overall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Negative = 243\n",
    "False Positive = 9\n",
    "False Negative = 15\n",
    "True Postive = 98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       252\n",
      "           1       0.92      0.87      0.89       113\n",
      "\n",
      "    accuracy                           0.93       365\n",
      "   macro avg       0.93      0.92      0.92       365\n",
      "weighted avg       0.93      0.93      0.93       365\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
